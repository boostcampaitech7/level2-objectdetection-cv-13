{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import torch\n",
    "import detectron2\n",
    "from detectron2.data import detection_utils as utils\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.evaluation import COCOEvaluator\n",
    "from detectron2.data import build_detection_test_loader, build_detection_train_loader\n",
    "\n",
    "MODEL_NAME = 'COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register Dataset\n",
    "try:\n",
    "    register_coco_instances('coco_trash_train', {}, '/data/ephemeral/home/baseline/detectron2/train_split.json', '../../dataset/')\n",
    "except AssertionError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    register_coco_instances('coco_trash_test', {}, '/data/ephemeral/home/baseline/detectron2/val_split.json', '../../dataset/')\n",
    "except AssertionError:\n",
    "    pass\n",
    "\n",
    "MetadataCatalog.get('coco_trash_train').thing_classes = [\"General trash\", \"Paper\", \"Paper pack\", \"Metal\", \n",
    "                                                         \"Glass\", \"Plastic\", \"Styrofoam\", \"Plastic bag\", \"Battery\", \"Clothing\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "masked_rcnn_test.yaml not available in Model Zoo!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/data/ephemeral/home/baseline/detectron2/faster_rcnn_train.ipynb Cell 4\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.28.224.166/data/ephemeral/home/baseline/detectron2/faster_rcnn_train.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# config 불러오기\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.28.224.166/data/ephemeral/home/baseline/detectron2/faster_rcnn_train.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m cfg \u001b[39m=\u001b[39m get_cfg()\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B10.28.224.166/data/ephemeral/home/baseline/detectron2/faster_rcnn_train.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m cfg\u001b[39m.\u001b[39mmerge_from_file(model_zoo\u001b[39m.\u001b[39;49mget_config_file(MODEL_NAME \u001b[39m+\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39m.yaml\u001b[39;49m\u001b[39m'\u001b[39;49m))\n",
      "File \u001b[0;32m~/baseline/detectron2/detectron2/model_zoo/model_zoo.py:143\u001b[0m, in \u001b[0;36mget_config_file\u001b[0;34m(config_path)\u001b[0m\n\u001b[1;32m    139\u001b[0m cfg_file \u001b[39m=\u001b[39m pkg_resources\u001b[39m.\u001b[39mresource_filename(\n\u001b[1;32m    140\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mdetectron2.model_zoo\u001b[39m\u001b[39m\"\u001b[39m, os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39m\"\u001b[39m\u001b[39mconfigs\u001b[39m\u001b[39m\"\u001b[39m, config_path)\n\u001b[1;32m    141\u001b[0m )\n\u001b[1;32m    142\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(cfg_file):\n\u001b[0;32m--> 143\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m not available in Model Zoo!\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(config_path))\n\u001b[1;32m    144\u001b[0m \u001b[39mreturn\u001b[39;00m cfg_file\n",
      "\u001b[0;31mRuntimeError\u001b[0m: masked_rcnn_test.yaml not available in Model Zoo!"
     ]
    }
   ],
   "source": [
    "# config 불러오기\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(MODEL_NAME + '.yaml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config 수정하기\n",
    "cfg.DATASETS.TRAIN = ('coco_trash_train',)\n",
    "cfg.DATASETS.TEST = ('coco_trash_test',)\n",
    "\n",
    "cfg.DATALOADER.NUM_WOREKRS = 4\n",
    "\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(MODEL_NAME + '.yaml')\n",
    "\n",
    "cfg.SOLVER.IMS_PER_BATCH = 4\n",
    "cfg.SOLVER.BASE_LR = 0.001\n",
    "cfg.SOLVER.MAX_ITER = 15000\n",
    "cfg.SOLVER.STEPS = (8000,12000)\n",
    "cfg.SOLVER.GAMMA = 0.005\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = 3000\n",
    "cfg.SOLVER.AMP.ENABLED=True\n",
    "cfg.OUTPUT_DIR = './output'\n",
    "\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 256\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 10\n",
    "\n",
    "cfg.TEST.EVAL_PERIOD = 3000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapper - input data를 어떤 형식으로 return할지 (따라서 augmnentation 등 데이터 전처리 포함 됨)\n",
    "import detectron2.data.transforms as T\n",
    "\n",
    "def MyMapper(dataset_dict):\n",
    "    dataset_dict = copy.deepcopy(dataset_dict)\n",
    "    image = utils.read_image(dataset_dict['file_name'], format='BGR')\n",
    "    \n",
    "    transform_list = [\n",
    "        T.RandomFlip(prob=0.5, horizontal=False, vertical=True),\n",
    "        T.RandomBrightness(0.8, 1.8),\n",
    "        T.RandomContrast(0.6, 1.3)\n",
    "    ]\n",
    "    \n",
    "    image, transforms = T.apply_transform_gens(transform_list, image)\n",
    "    \n",
    "    dataset_dict['image'] = torch.as_tensor(image.transpose(2,0,1).astype('float32'))\n",
    "    \n",
    "    annos = [\n",
    "        utils.transform_instance_annotations(obj, transforms, image.shape[:2])\n",
    "        for obj in dataset_dict.pop('annotations')\n",
    "        if obj.get('iscrowd', 0) == 0\n",
    "    ]\n",
    "    \n",
    "    instances = utils.annotations_to_instances(annos, image.shape[:2])\n",
    "    dataset_dict['instances'] = utils.filter_empty_instances(instances)\n",
    "    \n",
    "    return dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer - DefaultTrainer를 상속\n",
    "class MyTrainer(DefaultTrainer):\n",
    "    \n",
    "    @classmethod\n",
    "    def build_train_loader(cls, cfg, sampler=None):\n",
    "        return build_detection_train_loader(\n",
    "        cfg, mapper = MyMapper, sampler = sampler\n",
    "        )\n",
    "    \n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        if output_folder is None:\n",
    "            os.makedirs('./output_eval', exist_ok = True)\n",
    "            output_folder = './output_eval'\n",
    "            \n",
    "        return COCOEvaluator(dataset_name, cfg, False, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/07 14:44:07 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (6): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (7): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (8): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (9): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (10): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (11): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (12): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (13): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (14): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (15): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (16): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (17): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (18): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (19): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (20): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (21): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (22): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=11, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=40, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/07 14:44:07 d2.data.datasets.coco]: \u001b[0mLoaded 3906 images in COCO format from /data/ephemeral/home/baseline/detectron2/train_split.json\n",
      "\u001b[32m[10/07 14:44:07 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 3906 images left.\n",
      "\u001b[32m[10/07 14:44:07 d2.data.build]: \u001b[0mDistribution of instances among all 10 categories:\n",
      "\u001b[36m|   category    | #instances   |  category   | #instances   |  category  | #instances   |\n",
      "|:-------------:|:-------------|:-----------:|:-------------|:----------:|:-------------|\n",
      "| General trash | 3131         |    Paper    | 5216         | Paper pack | 723          |\n",
      "|     Metal     | 725          |    Glass    | 805          |  Plastic   | 2390         |\n",
      "|   Styrofoam   | 968          | Plastic bag | 4114         |  Battery   | 118          |\n",
      "|   Clothing    | 385          |             |              |            |              |\n",
      "|     total     | 18575        |             |              |            |              |\u001b[0m\n",
      "\u001b[32m[10/07 14:44:07 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/07 14:44:07 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[10/07 14:44:07 d2.data.common]: \u001b[0mSerializing 3906 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/07 14:44:07 d2.data.common]: \u001b[0mSerialized dataset takes 1.75 MiB\n",
      "\u001b[32m[10/07 14:44:07 d2.data.build]: \u001b[0mMaking batched data loader with batch_size=4\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/07 14:44:07 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n",
      "\u001b[32m[10/07 14:44:07 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_101_FPN_3x/137851257/model_final_f6e8b1.pkl ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_final_f6e8b1.pkl: 243MB [00:04, 55.8MB/s]                              \n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (11, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (11,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (40, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (40,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/07 14:44:12 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/07 14:44:19 d2.utils.events]: \u001b[0m eta: 0:12:25  iter: 19  total_loss: 3.057  loss_cls: 2.265  loss_box_reg: 0.6652  loss_rpn_cls: 0.0576  loss_rpn_loc: 0.01841    time: 0.2511  last_time: 0.2494  data_time: 0.0273  last_data_time: 0.0152   lr: 1.9981e-05  max_mem: 3481M\n",
      "\u001b[32m[10/07 14:44:24 d2.utils.events]: \u001b[0m eta: 0:12:16  iter: 39  total_loss: 2.597  loss_cls: 1.806  loss_box_reg: 0.7051  loss_rpn_cls: 0.0248  loss_rpn_loc: 0.02146    time: 0.2494  last_time: 0.2472  data_time: 0.0158  last_data_time: 0.0157   lr: 3.9961e-05  max_mem: 3481M\n",
      "\u001b[32m[10/07 14:44:29 d2.utils.events]: \u001b[0m eta: 0:12:13  iter: 59  total_loss: 1.942  loss_cls: 1.036  loss_box_reg: 0.6745  loss_rpn_cls: 0.1465  loss_rpn_loc: 0.03242    time: 0.2505  last_time: 0.2495  data_time: 0.0165  last_data_time: 0.0155   lr: 5.9941e-05  max_mem: 3481M\n",
      "\u001b[32m[10/07 14:44:34 d2.utils.events]: \u001b[0m eta: 0:12:08  iter: 79  total_loss: 1.55  loss_cls: 0.7453  loss_box_reg: 0.6645  loss_rpn_cls: 0.06523  loss_rpn_loc: 0.03131    time: 0.2504  last_time: 0.2478  data_time: 0.0173  last_data_time: 0.0153   lr: 7.9921e-05  max_mem: 3481M\n",
      "\u001b[32m[10/07 14:44:39 d2.utils.events]: \u001b[0m eta: 0:12:02  iter: 99  total_loss: 1.545  loss_cls: 0.7213  loss_box_reg: 0.7031  loss_rpn_cls: 0.05888  loss_rpn_loc: 0.02466    time: 0.2500  last_time: 0.2467  data_time: 0.0162  last_data_time: 0.0157   lr: 9.9901e-05  max_mem: 3481M\n",
      "\u001b[32m[10/07 14:44:44 d2.utils.events]: \u001b[0m eta: 0:11:58  iter: 119  total_loss: 1.479  loss_cls: 0.6724  loss_box_reg: 0.6838  loss_rpn_cls: 0.03305  loss_rpn_loc: 0.02548    time: 0.2503  last_time: 0.2510  data_time: 0.0159  last_data_time: 0.0159   lr: 0.00011988  max_mem: 3481M\n",
      "\u001b[32m[10/07 14:44:49 d2.utils.events]: \u001b[0m eta: 0:11:54  iter: 139  total_loss: 1.782  loss_cls: 0.8124  loss_box_reg: 0.8122  loss_rpn_cls: 0.08327  loss_rpn_loc: 0.03311    time: 0.2508  last_time: 0.2615  data_time: 0.0165  last_data_time: 0.0160   lr: 0.00013986  max_mem: 3481M\n",
      "\u001b[32m[10/07 14:44:55 d2.utils.events]: \u001b[0m eta: 0:11:51  iter: 159  total_loss: 1.39  loss_cls: 0.6402  loss_box_reg: 0.7021  loss_rpn_cls: 0.03229  loss_rpn_loc: 0.01842    time: 0.2518  last_time: 0.2517  data_time: 0.0167  last_data_time: 0.0159   lr: 0.00015984  max_mem: 3481M\n",
      "\u001b[32m[10/07 14:45:00 d2.utils.events]: \u001b[0m eta: 0:11:48  iter: 179  total_loss: 1.487  loss_cls: 0.6404  loss_box_reg: 0.6962  loss_rpn_cls: 0.03199  loss_rpn_loc: 0.03086    time: 0.2521  last_time: 0.2488  data_time: 0.0170  last_data_time: 0.0148   lr: 0.00017982  max_mem: 3481M\n",
      "\u001b[32m[10/07 14:45:05 d2.utils.events]: \u001b[0m eta: 0:11:43  iter: 199  total_loss: 1.476  loss_cls: 0.6912  loss_box_reg: 0.7118  loss_rpn_cls: 0.03389  loss_rpn_loc: 0.03673    time: 0.2522  last_time: 0.2561  data_time: 0.0173  last_data_time: 0.0162   lr: 0.0001998  max_mem: 3481M\n",
      "\u001b[32m[10/07 14:45:10 d2.utils.events]: \u001b[0m eta: 0:11:38  iter: 219  total_loss: 1.37  loss_cls: 0.6184  loss_box_reg: 0.6912  loss_rpn_cls: 0.02006  loss_rpn_loc: 0.02326    time: 0.2523  last_time: 0.2509  data_time: 0.0169  last_data_time: 0.0159   lr: 0.00021978  max_mem: 3481M\n",
      "\u001b[32m[10/07 14:45:15 d2.utils.events]: \u001b[0m eta: 0:11:33  iter: 239  total_loss: 1.478  loss_cls: 0.6584  loss_box_reg: 0.688  loss_rpn_cls: 0.02901  loss_rpn_loc: 0.03415    time: 0.2524  last_time: 0.2569  data_time: 0.0178  last_data_time: 0.0218   lr: 0.00023976  max_mem: 3481M\n",
      "\u001b[32m[10/07 14:45:20 d2.utils.events]: \u001b[0m eta: 0:11:29  iter: 259  total_loss: 1.394  loss_cls: 0.6135  loss_box_reg: 0.6363  loss_rpn_cls: 0.03066  loss_rpn_loc: 0.02938    time: 0.2530  last_time: 0.2633  data_time: 0.0162  last_data_time: 0.0159   lr: 0.00025974  max_mem: 3481M\n",
      "\u001b[32m[10/07 14:45:26 d2.utils.events]: \u001b[0m eta: 0:11:25  iter: 279  total_loss: 1.403  loss_cls: 0.6298  loss_box_reg: 0.6843  loss_rpn_cls: 0.03036  loss_rpn_loc: 0.02702    time: 0.2537  last_time: 0.2513  data_time: 0.0160  last_data_time: 0.0163   lr: 0.00027972  max_mem: 3481M\n",
      "\u001b[32m[10/07 14:45:31 d2.utils.events]: \u001b[0m eta: 0:11:20  iter: 299  total_loss: 1.334  loss_cls: 0.612  loss_box_reg: 0.6261  loss_rpn_cls: 0.03445  loss_rpn_loc: 0.02916    time: 0.2537  last_time: 0.2540  data_time: 0.0175  last_data_time: 0.0161   lr: 0.0002997  max_mem: 3481M\n",
      "\u001b[32m[10/07 14:45:36 d2.utils.events]: \u001b[0m eta: 0:11:15  iter: 319  total_loss: 1.185  loss_cls: 0.5335  loss_box_reg: 0.5804  loss_rpn_cls: 0.04445  loss_rpn_loc: 0.02354    time: 0.2536  last_time: 0.2532  data_time: 0.0168  last_data_time: 0.0168   lr: 0.00031968  max_mem: 3481M\n",
      "\u001b[32m[10/07 14:45:41 d2.utils.events]: \u001b[0m eta: 0:11:10  iter: 339  total_loss: 1.135  loss_cls: 0.5233  loss_box_reg: 0.5576  loss_rpn_cls: 0.03051  loss_rpn_loc: 0.02171    time: 0.2534  last_time: 0.2498  data_time: 0.0162  last_data_time: 0.0162   lr: 0.00033966  max_mem: 3481M\n",
      "\u001b[32m[10/07 14:45:46 d2.utils.events]: \u001b[0m eta: 0:11:04  iter: 359  total_loss: 1.358  loss_cls: 0.6697  loss_box_reg: 0.5812  loss_rpn_cls: 0.03499  loss_rpn_loc: 0.03038    time: 0.2532  last_time: 0.2478  data_time: 0.0160  last_data_time: 0.0159   lr: 0.00035964  max_mem: 3481M\n",
      "\u001b[32m[10/07 14:45:51 d2.utils.events]: \u001b[0m eta: 0:10:59  iter: 379  total_loss: 1.089  loss_cls: 0.5445  loss_box_reg: 0.4867  loss_rpn_cls: 0.02764  loss_rpn_loc: 0.02554    time: 0.2532  last_time: 0.2540  data_time: 0.0182  last_data_time: 0.0167   lr: 0.00037962  max_mem: 3481M\n",
      "\u001b[32m[10/07 14:45:56 d2.utils.events]: \u001b[0m eta: 0:10:54  iter: 399  total_loss: 1.116  loss_cls: 0.5663  loss_box_reg: 0.4737  loss_rpn_cls: 0.03181  loss_rpn_loc: 0.03438    time: 0.2530  last_time: 0.2482  data_time: 0.0168  last_data_time: 0.0171   lr: 0.0003996  max_mem: 3481M\n",
      "\u001b[32m[10/07 14:46:01 d2.utils.events]: \u001b[0m eta: 0:10:48  iter: 419  total_loss: 1.177  loss_cls: 0.6105  loss_box_reg: 0.4293  loss_rpn_cls: 0.03442  loss_rpn_loc: 0.02968    time: 0.2528  last_time: 0.2449  data_time: 0.0164  last_data_time: 0.0156   lr: 0.00041958  max_mem: 3481M\n",
      "\u001b[32m[10/07 14:46:06 d2.utils.events]: \u001b[0m eta: 0:10:43  iter: 439  total_loss: 1.019  loss_cls: 0.5321  loss_box_reg: 0.3951  loss_rpn_cls: 0.0292  loss_rpn_loc: 0.03114    time: 0.2527  last_time: 0.2539  data_time: 0.0169  last_data_time: 0.0162   lr: 0.00043956  max_mem: 3481M\n",
      "\u001b[32m[10/07 14:46:11 d2.utils.events]: \u001b[0m eta: 0:10:38  iter: 459  total_loss: 1.099  loss_cls: 0.5399  loss_box_reg: 0.444  loss_rpn_cls: 0.0232  loss_rpn_loc: 0.02738    time: 0.2527  last_time: 0.2553  data_time: 0.0170  last_data_time: 0.0169   lr: 0.00045954  max_mem: 3481M\n",
      "\u001b[32m[10/07 14:46:16 d2.utils.events]: \u001b[0m eta: 0:10:33  iter: 479  total_loss: 1.089  loss_cls: 0.5214  loss_box_reg: 0.435  loss_rpn_cls: 0.03584  loss_rpn_loc: 0.02771    time: 0.2528  last_time: 0.2510  data_time: 0.0183  last_data_time: 0.0167   lr: 0.00047952  max_mem: 3481M\n",
      "\u001b[32m[10/07 14:46:22 d2.utils.events]: \u001b[0m eta: 0:10:28  iter: 499  total_loss: 0.8616  loss_cls: 0.4409  loss_box_reg: 0.3227  loss_rpn_cls: 0.02708  loss_rpn_loc: 0.04466    time: 0.2529  last_time: 0.2510  data_time: 0.0177  last_data_time: 0.0163   lr: 0.0004995  max_mem: 3481M\n",
      "\u001b[32m[10/07 14:46:27 d2.utils.events]: \u001b[0m eta: 0:10:23  iter: 519  total_loss: 1.1  loss_cls: 0.5722  loss_box_reg: 0.4413  loss_rpn_cls: 0.03398  loss_rpn_loc: 0.03311    time: 0.2529  last_time: 0.2539  data_time: 0.0167  last_data_time: 0.0168   lr: 0.00051948  max_mem: 3481M\n",
      "\u001b[32m[10/07 14:46:32 d2.utils.events]: \u001b[0m eta: 0:10:19  iter: 539  total_loss: 0.8268  loss_cls: 0.4339  loss_box_reg: 0.3573  loss_rpn_cls: 0.02247  loss_rpn_loc: 0.02456    time: 0.2529  last_time: 0.2698  data_time: 0.0166  last_data_time: 0.0165   lr: 0.00053946  max_mem: 3481M\n",
      "\u001b[32m[10/07 14:46:37 d2.utils.events]: \u001b[0m eta: 0:10:14  iter: 559  total_loss: 1.038  loss_cls: 0.5418  loss_box_reg: 0.4291  loss_rpn_cls: 0.04021  loss_rpn_loc: 0.0321    time: 0.2529  last_time: 0.2545  data_time: 0.0163  last_data_time: 0.0152   lr: 0.00055944  max_mem: 3481M\n",
      "\u001b[32m[10/07 14:46:42 d2.utils.events]: \u001b[0m eta: 0:10:09  iter: 579  total_loss: 0.9391  loss_cls: 0.4804  loss_box_reg: 0.3808  loss_rpn_cls: 0.02909  loss_rpn_loc: 0.01731    time: 0.2529  last_time: 0.2548  data_time: 0.0165  last_data_time: 0.0183   lr: 0.00057942  max_mem: 3481M\n",
      "\u001b[32m[10/07 14:46:47 d2.utils.events]: \u001b[0m eta: 0:10:04  iter: 599  total_loss: 1.092  loss_cls: 0.5867  loss_box_reg: 0.3766  loss_rpn_cls: 0.03234  loss_rpn_loc: 0.0276    time: 0.2529  last_time: 0.2527  data_time: 0.0169  last_data_time: 0.0161   lr: 0.0005994  max_mem: 3481M\n",
      "\u001b[32m[10/07 14:46:52 d2.utils.events]: \u001b[0m eta: 0:09:59  iter: 619  total_loss: 0.9633  loss_cls: 0.4977  loss_box_reg: 0.3739  loss_rpn_cls: 0.03052  loss_rpn_loc: 0.03064    time: 0.2528  last_time: 0.2495  data_time: 0.0159  last_data_time: 0.0156   lr: 0.00061938  max_mem: 3481M\n",
      "\u001b[32m[10/07 14:46:57 d2.utils.events]: \u001b[0m eta: 0:09:53  iter: 639  total_loss: 0.926  loss_cls: 0.4501  loss_box_reg: 0.3318  loss_rpn_cls: 0.02026  loss_rpn_loc: 0.03336    time: 0.2528  last_time: 0.2491  data_time: 0.0161  last_data_time: 0.0159   lr: 0.00063936  max_mem: 3481M\n",
      "\u001b[32m[10/07 14:47:02 d2.utils.events]: \u001b[0m eta: 0:09:48  iter: 659  total_loss: 0.9048  loss_cls: 0.4742  loss_box_reg: 0.3502  loss_rpn_cls: 0.02666  loss_rpn_loc: 0.02307    time: 0.2529  last_time: 0.2501  data_time: 0.0172  last_data_time: 0.0163   lr: 0.00065934  max_mem: 3481M\n",
      "\u001b[32m[10/07 14:47:07 d2.utils.events]: \u001b[0m eta: 0:09:43  iter: 679  total_loss: 0.9923  loss_cls: 0.537  loss_box_reg: 0.3418  loss_rpn_cls: 0.02607  loss_rpn_loc: 0.02571    time: 0.2529  last_time: 0.2521  data_time: 0.0166  last_data_time: 0.0165   lr: 0.00067932  max_mem: 3481M\n",
      "\u001b[32m[10/07 14:47:13 d2.utils.events]: \u001b[0m eta: 0:09:38  iter: 699  total_loss: 0.8087  loss_cls: 0.5045  loss_box_reg: 0.2736  loss_rpn_cls: 0.02753  loss_rpn_loc: 0.0341    time: 0.2529  last_time: 0.2433  data_time: 0.0172  last_data_time: 0.0142   lr: 0.0006993  max_mem: 3481M\n",
      "\u001b[32m[10/07 14:47:18 d2.utils.events]: \u001b[0m eta: 0:09:33  iter: 719  total_loss: 0.9557  loss_cls: 0.4926  loss_box_reg: 0.3565  loss_rpn_cls: 0.03036  loss_rpn_loc: 0.03072    time: 0.2529  last_time: 0.2498  data_time: 0.0171  last_data_time: 0.0166   lr: 0.00071928  max_mem: 3481M\n",
      "\u001b[32m[10/07 14:47:23 d2.utils.events]: \u001b[0m eta: 0:09:28  iter: 739  total_loss: 0.9502  loss_cls: 0.5088  loss_box_reg: 0.3333  loss_rpn_cls: 0.03305  loss_rpn_loc: 0.03178    time: 0.2528  last_time: 0.2503  data_time: 0.0162  last_data_time: 0.0161   lr: 0.00073926  max_mem: 3481M\n",
      "\u001b[32m[10/07 14:47:28 d2.utils.events]: \u001b[0m eta: 0:09:23  iter: 759  total_loss: 0.8885  loss_cls: 0.4616  loss_box_reg: 0.3069  loss_rpn_cls: 0.03327  loss_rpn_loc: 0.02648    time: 0.2528  last_time: 0.2489  data_time: 0.0165  last_data_time: 0.0163   lr: 0.00075924  max_mem: 3481M\n",
      "\u001b[32m[10/07 14:47:33 d2.utils.events]: \u001b[0m eta: 0:09:18  iter: 779  total_loss: 0.912  loss_cls: 0.4617  loss_box_reg: 0.3326  loss_rpn_cls: 0.02669  loss_rpn_loc: 0.03252    time: 0.2527  last_time: 0.2517  data_time: 0.0168  last_data_time: 0.0164   lr: 0.00077922  max_mem: 3481M\n",
      "\u001b[32m[10/07 14:47:38 d2.utils.events]: \u001b[0m eta: 0:09:13  iter: 799  total_loss: 0.8892  loss_cls: 0.4757  loss_box_reg: 0.3194  loss_rpn_cls: 0.0202  loss_rpn_loc: 0.03255    time: 0.2527  last_time: 0.2533  data_time: 0.0176  last_data_time: 0.0190   lr: 0.0007992  max_mem: 3481M\n",
      "\u001b[32m[10/07 14:47:43 d2.utils.events]: \u001b[0m eta: 0:09:08  iter: 819  total_loss: 0.781  loss_cls: 0.4577  loss_box_reg: 0.2954  loss_rpn_cls: 0.02057  loss_rpn_loc: 0.01556    time: 0.2527  last_time: 0.2483  data_time: 0.0163  last_data_time: 0.0160   lr: 0.00081918  max_mem: 3481M\n",
      "\u001b[32m[10/07 14:47:48 d2.utils.events]: \u001b[0m eta: 0:09:03  iter: 839  total_loss: 1.109  loss_cls: 0.6068  loss_box_reg: 0.3739  loss_rpn_cls: 0.03788  loss_rpn_loc: 0.04953    time: 0.2527  last_time: 0.2495  data_time: 0.0162  last_data_time: 0.0159   lr: 0.00083916  max_mem: 3481M\n",
      "\u001b[32m[10/07 14:47:53 d2.utils.events]: \u001b[0m eta: 0:08:58  iter: 859  total_loss: 0.9705  loss_cls: 0.4849  loss_box_reg: 0.3525  loss_rpn_cls: 0.02606  loss_rpn_loc: 0.02542    time: 0.2526  last_time: 0.2495  data_time: 0.0158  last_data_time: 0.0159   lr: 0.00085914  max_mem: 3481M\n",
      "\u001b[32m[10/07 14:47:58 d2.utils.events]: \u001b[0m eta: 0:08:52  iter: 879  total_loss: 0.9127  loss_cls: 0.4915  loss_box_reg: 0.3005  loss_rpn_cls: 0.04078  loss_rpn_loc: 0.03255    time: 0.2526  last_time: 0.2560  data_time: 0.0159  last_data_time: 0.0159   lr: 0.00087912  max_mem: 3504M\n",
      "\u001b[32m[10/07 14:48:03 d2.utils.events]: \u001b[0m eta: 0:08:47  iter: 899  total_loss: 0.9038  loss_cls: 0.512  loss_box_reg: 0.3199  loss_rpn_cls: 0.02067  loss_rpn_loc: 0.02641    time: 0.2526  last_time: 0.2485  data_time: 0.0182  last_data_time: 0.0161   lr: 0.0008991  max_mem: 3504M\n",
      "\u001b[32m[10/07 14:48:08 d2.utils.events]: \u001b[0m eta: 0:08:42  iter: 919  total_loss: 0.9205  loss_cls: 0.5171  loss_box_reg: 0.2889  loss_rpn_cls: 0.01581  loss_rpn_loc: 0.02137    time: 0.2527  last_time: 0.2677  data_time: 0.0181  last_data_time: 0.0207   lr: 0.00091908  max_mem: 3504M\n",
      "\u001b[32m[10/07 14:48:14 d2.utils.events]: \u001b[0m eta: 0:08:37  iter: 939  total_loss: 0.9388  loss_cls: 0.5083  loss_box_reg: 0.3286  loss_rpn_cls: 0.03334  loss_rpn_loc: 0.02939    time: 0.2527  last_time: 0.2581  data_time: 0.0177  last_data_time: 0.0169   lr: 0.00093906  max_mem: 3504M\n",
      "\u001b[32m[10/07 14:48:19 d2.utils.events]: \u001b[0m eta: 0:08:32  iter: 959  total_loss: 0.8074  loss_cls: 0.4737  loss_box_reg: 0.2774  loss_rpn_cls: 0.01941  loss_rpn_loc: 0.01579    time: 0.2527  last_time: 0.2478  data_time: 0.0164  last_data_time: 0.0162   lr: 0.00095904  max_mem: 3504M\n",
      "\u001b[32m[10/07 14:48:24 d2.utils.events]: \u001b[0m eta: 0:08:27  iter: 979  total_loss: 0.7357  loss_cls: 0.4112  loss_box_reg: 0.2689  loss_rpn_cls: 0.01485  loss_rpn_loc: 0.0155    time: 0.2526  last_time: 0.2487  data_time: 0.0163  last_data_time: 0.0158   lr: 0.00097902  max_mem: 3504M\n",
      "\u001b[32m[10/07 14:48:29 d2.utils.events]: \u001b[0m eta: 0:08:22  iter: 999  total_loss: 0.8886  loss_cls: 0.4627  loss_box_reg: 0.3319  loss_rpn_cls: 0.02573  loss_rpn_loc: 0.03722    time: 0.2527  last_time: 0.2627  data_time: 0.0198  last_data_time: 0.0167   lr: 0.000999  max_mem: 3504M\n",
      "\u001b[32m[10/07 14:48:34 d2.utils.events]: \u001b[0m eta: 0:08:17  iter: 1019  total_loss: 0.7863  loss_cls: 0.4427  loss_box_reg: 0.2698  loss_rpn_cls: 0.01424  loss_rpn_loc: 0.02561    time: 0.2528  last_time: 0.2611  data_time: 0.0167  last_data_time: 0.0169   lr: 0.001  max_mem: 3504M\n",
      "\u001b[32m[10/07 14:48:39 d2.utils.events]: \u001b[0m eta: 0:08:13  iter: 1039  total_loss: 0.8491  loss_cls: 0.4747  loss_box_reg: 0.3037  loss_rpn_cls: 0.0238  loss_rpn_loc: 0.02068    time: 0.2529  last_time: 0.2517  data_time: 0.0175  last_data_time: 0.0154   lr: 0.001  max_mem: 3504M\n",
      "\u001b[32m[10/07 14:48:44 d2.utils.events]: \u001b[0m eta: 0:08:08  iter: 1059  total_loss: 0.8504  loss_cls: 0.4281  loss_box_reg: 0.3138  loss_rpn_cls: 0.02457  loss_rpn_loc: 0.01697    time: 0.2529  last_time: 0.2493  data_time: 0.0169  last_data_time: 0.0162   lr: 0.001  max_mem: 3504M\n",
      "\u001b[32m[10/07 14:48:49 d2.utils.events]: \u001b[0m eta: 0:08:03  iter: 1079  total_loss: 0.853  loss_cls: 0.4741  loss_box_reg: 0.2758  loss_rpn_cls: 0.02712  loss_rpn_loc: 0.02797    time: 0.2529  last_time: 0.2549  data_time: 0.0169  last_data_time: 0.0184   lr: 0.001  max_mem: 3504M\n",
      "\u001b[32m[10/07 14:48:55 d2.utils.events]: \u001b[0m eta: 0:07:58  iter: 1099  total_loss: 0.8584  loss_cls: 0.4844  loss_box_reg: 0.3099  loss_rpn_cls: 0.02902  loss_rpn_loc: 0.02242    time: 0.2529  last_time: 0.2562  data_time: 0.0168  last_data_time: 0.0193   lr: 0.001  max_mem: 3504M\n",
      "\u001b[32m[10/07 14:49:00 d2.utils.events]: \u001b[0m eta: 0:07:53  iter: 1119  total_loss: 0.9156  loss_cls: 0.4774  loss_box_reg: 0.3151  loss_rpn_cls: 0.0411  loss_rpn_loc: 0.03425    time: 0.2529  last_time: 0.2523  data_time: 0.0175  last_data_time: 0.0182   lr: 0.001  max_mem: 3504M\n",
      "\u001b[32m[10/07 14:49:05 d2.utils.events]: \u001b[0m eta: 0:07:48  iter: 1139  total_loss: 0.8841  loss_cls: 0.5119  loss_box_reg: 0.3513  loss_rpn_cls: 0.02438  loss_rpn_loc: 0.02964    time: 0.2530  last_time: 0.2620  data_time: 0.0188  last_data_time: 0.0164   lr: 0.001  max_mem: 3504M\n",
      "\u001b[32m[10/07 14:49:10 d2.utils.events]: \u001b[0m eta: 0:07:43  iter: 1159  total_loss: 0.9198  loss_cls: 0.4746  loss_box_reg: 0.3078  loss_rpn_cls: 0.02182  loss_rpn_loc: 0.02298    time: 0.2530  last_time: 0.2583  data_time: 0.0169  last_data_time: 0.0148   lr: 0.001  max_mem: 3504M\n",
      "\u001b[32m[10/07 14:49:15 d2.utils.events]: \u001b[0m eta: 0:07:38  iter: 1179  total_loss: 0.8056  loss_cls: 0.4164  loss_box_reg: 0.3006  loss_rpn_cls: 0.01554  loss_rpn_loc: 0.02439    time: 0.2531  last_time: 0.2496  data_time: 0.0171  last_data_time: 0.0168   lr: 0.001  max_mem: 3504M\n",
      "\u001b[32m[10/07 14:49:20 d2.utils.events]: \u001b[0m eta: 0:07:33  iter: 1199  total_loss: 0.8881  loss_cls: 0.4633  loss_box_reg: 0.3136  loss_rpn_cls: 0.02232  loss_rpn_loc: 0.04192    time: 0.2531  last_time: 0.2517  data_time: 0.0179  last_data_time: 0.0161   lr: 0.001  max_mem: 3504M\n",
      "\u001b[32m[10/07 14:49:25 d2.utils.events]: \u001b[0m eta: 0:07:28  iter: 1219  total_loss: 0.8436  loss_cls: 0.4542  loss_box_reg: 0.2943  loss_rpn_cls: 0.02572  loss_rpn_loc: 0.02103    time: 0.2531  last_time: 0.2535  data_time: 0.0179  last_data_time: 0.0162   lr: 0.001  max_mem: 3504M\n",
      "\u001b[32m[10/07 14:49:31 d2.utils.events]: \u001b[0m eta: 0:07:23  iter: 1239  total_loss: 0.6958  loss_cls: 0.404  loss_box_reg: 0.2594  loss_rpn_cls: 0.01871  loss_rpn_loc: 0.02248    time: 0.2531  last_time: 0.2516  data_time: 0.0172  last_data_time: 0.0168   lr: 0.001  max_mem: 3504M\n",
      "\u001b[32m[10/07 14:49:36 d2.utils.events]: \u001b[0m eta: 0:07:18  iter: 1259  total_loss: 0.7921  loss_cls: 0.4733  loss_box_reg: 0.2806  loss_rpn_cls: 0.02109  loss_rpn_loc: 0.0138    time: 0.2532  last_time: 0.2520  data_time: 0.0176  last_data_time: 0.0178   lr: 0.001  max_mem: 3504M\n",
      "\u001b[32m[10/07 14:49:41 d2.utils.events]: \u001b[0m eta: 0:07:12  iter: 1279  total_loss: 0.6726  loss_cls: 0.3883  loss_box_reg: 0.2366  loss_rpn_cls: 0.01577  loss_rpn_loc: 0.01884    time: 0.2531  last_time: 0.2608  data_time: 0.0173  last_data_time: 0.0158   lr: 0.001  max_mem: 3504M\n",
      "\u001b[32m[10/07 14:49:46 d2.utils.events]: \u001b[0m eta: 0:07:07  iter: 1299  total_loss: 0.8232  loss_cls: 0.4939  loss_box_reg: 0.3182  loss_rpn_cls: 0.01923  loss_rpn_loc: 0.01704    time: 0.2531  last_time: 0.2511  data_time: 0.0169  last_data_time: 0.0165   lr: 0.001  max_mem: 3504M\n",
      "\u001b[32m[10/07 14:49:51 d2.utils.events]: \u001b[0m eta: 0:07:02  iter: 1319  total_loss: 0.8794  loss_cls: 0.4566  loss_box_reg: 0.3229  loss_rpn_cls: 0.02553  loss_rpn_loc: 0.04127    time: 0.2531  last_time: 0.2515  data_time: 0.0170  last_data_time: 0.0166   lr: 0.001  max_mem: 3504M\n",
      "\u001b[32m[10/07 14:49:56 d2.utils.events]: \u001b[0m eta: 0:06:57  iter: 1339  total_loss: 0.9744  loss_cls: 0.5021  loss_box_reg: 0.34  loss_rpn_cls: 0.03979  loss_rpn_loc: 0.04829    time: 0.2531  last_time: 0.2509  data_time: 0.0170  last_data_time: 0.0183   lr: 0.001  max_mem: 3504M\n",
      "\u001b[32m[10/07 14:50:01 d2.utils.events]: \u001b[0m eta: 0:06:52  iter: 1359  total_loss: 0.9017  loss_cls: 0.5006  loss_box_reg: 0.2744  loss_rpn_cls: 0.02264  loss_rpn_loc: 0.03273    time: 0.2531  last_time: 0.2521  data_time: 0.0173  last_data_time: 0.0166   lr: 0.001  max_mem: 3504M\n",
      "\u001b[32m[10/07 14:50:06 d2.utils.events]: \u001b[0m eta: 0:06:47  iter: 1379  total_loss: 0.8065  loss_cls: 0.473  loss_box_reg: 0.2928  loss_rpn_cls: 0.02456  loss_rpn_loc: 0.02134    time: 0.2531  last_time: 0.2465  data_time: 0.0175  last_data_time: 0.0140   lr: 0.001  max_mem: 3504M\n",
      "\u001b[32m[10/07 14:50:11 d2.utils.events]: \u001b[0m eta: 0:06:42  iter: 1399  total_loss: 0.8152  loss_cls: 0.4696  loss_box_reg: 0.3029  loss_rpn_cls: 0.02511  loss_rpn_loc: 0.02522    time: 0.2530  last_time: 0.2619  data_time: 0.0158  last_data_time: 0.0152   lr: 0.001  max_mem: 3504M\n",
      "\u001b[32m[10/07 14:50:16 d2.utils.events]: \u001b[0m eta: 0:06:37  iter: 1419  total_loss: 0.6362  loss_cls: 0.3647  loss_box_reg: 0.2444  loss_rpn_cls: 0.01639  loss_rpn_loc: 0.01321    time: 0.2530  last_time: 0.2482  data_time: 0.0163  last_data_time: 0.0162   lr: 0.001  max_mem: 3504M\n",
      "\u001b[32m[10/07 14:50:21 d2.utils.events]: \u001b[0m eta: 0:06:32  iter: 1439  total_loss: 0.9512  loss_cls: 0.4788  loss_box_reg: 0.327  loss_rpn_cls: 0.02705  loss_rpn_loc: 0.02204    time: 0.2530  last_time: 0.2644  data_time: 0.0161  last_data_time: 0.0160   lr: 0.001  max_mem: 3504M\n",
      "\u001b[32m[10/07 14:50:27 d2.utils.events]: \u001b[0m eta: 0:06:27  iter: 1459  total_loss: 0.8442  loss_cls: 0.4568  loss_box_reg: 0.3007  loss_rpn_cls: 0.02497  loss_rpn_loc: 0.03319    time: 0.2530  last_time: 0.2533  data_time: 0.0175  last_data_time: 0.0169   lr: 0.001  max_mem: 3504M\n",
      "\u001b[32m[10/07 14:50:32 d2.utils.events]: \u001b[0m eta: 0:06:22  iter: 1479  total_loss: 0.7864  loss_cls: 0.4249  loss_box_reg: 0.2847  loss_rpn_cls: 0.02577  loss_rpn_loc: 0.03296    time: 0.2531  last_time: 0.2502  data_time: 0.0180  last_data_time: 0.0164   lr: 0.001  max_mem: 3504M\n",
      "\u001b[32m[10/07 14:50:38 d2.data.datasets.coco]: \u001b[0mLoaded 977 images in COCO format from /data/ephemeral/home/baseline/detectron2/val_split.json\n",
      "\u001b[32m[10/07 14:50:38 d2.data.build]: \u001b[0mDistribution of instances among all 10 categories:\n",
      "\u001b[36m|   category    | #instances   |  category   | #instances   |  category  | #instances   |\n",
      "|:-------------:|:-------------|:-----------:|:-------------|:----------:|:-------------|\n",
      "| General trash | 835          |    Paper    | 1136         | Paper pack | 174          |\n",
      "|     Metal     | 211          |    Glass    | 177          |  Plastic   | 553          |\n",
      "|   Styrofoam   | 295          | Plastic bag | 1064         |  Battery   | 41           |\n",
      "|   Clothing    | 83           |             |              |            |              |\n",
      "|     total     | 4569         |             |              |            |              |\u001b[0m\n",
      "\u001b[32m[10/07 14:50:38 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/07 14:50:38 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[10/07 14:50:38 d2.data.common]: \u001b[0mSerializing 977 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/07 14:50:38 d2.data.common]: \u001b[0mSerialized dataset takes 0.43 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/07 14:50:38 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[10/07 14:50:38 d2.evaluation.evaluator]: \u001b[0mStart inference on 977 batches\n",
      "\u001b[32m[10/07 14:50:39 d2.evaluation.evaluator]: \u001b[0mInference done 11/977. Dataloading: 0.0011 s/iter. Inference: 0.0458 s/iter. Eval: 0.0003 s/iter. Total: 0.0473 s/iter. ETA=0:00:45\n",
      "\u001b[32m[10/07 14:50:44 d2.evaluation.evaluator]: \u001b[0mInference done 118/977. Dataloading: 0.0014 s/iter. Inference: 0.0454 s/iter. Eval: 0.0003 s/iter. Total: 0.0471 s/iter. ETA=0:00:40\n",
      "\u001b[32m[10/07 14:50:49 d2.evaluation.evaluator]: \u001b[0mInference done 223/977. Dataloading: 0.0014 s/iter. Inference: 0.0457 s/iter. Eval: 0.0003 s/iter. Total: 0.0474 s/iter. ETA=0:00:35\n",
      "\u001b[32m[10/07 14:50:54 d2.evaluation.evaluator]: \u001b[0mInference done 325/977. Dataloading: 0.0014 s/iter. Inference: 0.0462 s/iter. Eval: 0.0003 s/iter. Total: 0.0480 s/iter. ETA=0:00:31\n",
      "\u001b[32m[10/07 14:50:59 d2.evaluation.evaluator]: \u001b[0mInference done 427/977. Dataloading: 0.0015 s/iter. Inference: 0.0464 s/iter. Eval: 0.0007 s/iter. Total: 0.0486 s/iter. ETA=0:00:26\n",
      "\u001b[32m[10/07 14:51:04 d2.evaluation.evaluator]: \u001b[0mInference done 531/977. Dataloading: 0.0015 s/iter. Inference: 0.0464 s/iter. Eval: 0.0006 s/iter. Total: 0.0486 s/iter. ETA=0:00:21\n",
      "\u001b[32m[10/07 14:51:09 d2.evaluation.evaluator]: \u001b[0mInference done 630/977. Dataloading: 0.0015 s/iter. Inference: 0.0468 s/iter. Eval: 0.0006 s/iter. Total: 0.0489 s/iter. ETA=0:00:16\n",
      "\u001b[32m[10/07 14:51:14 d2.evaluation.evaluator]: \u001b[0mInference done 730/977. Dataloading: 0.0015 s/iter. Inference: 0.0470 s/iter. Eval: 0.0005 s/iter. Total: 0.0491 s/iter. ETA=0:00:12\n",
      "\u001b[32m[10/07 14:51:19 d2.evaluation.evaluator]: \u001b[0mInference done 827/977. Dataloading: 0.0015 s/iter. Inference: 0.0474 s/iter. Eval: 0.0005 s/iter. Total: 0.0494 s/iter. ETA=0:00:07\n",
      "\u001b[32m[10/07 14:51:24 d2.evaluation.evaluator]: \u001b[0mInference done 921/977. Dataloading: 0.0015 s/iter. Inference: 0.0478 s/iter. Eval: 0.0005 s/iter. Total: 0.0498 s/iter. ETA=0:00:02\n",
      "\u001b[32m[10/07 14:51:27 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:48.409504 (0.049804 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/07 14:51:27 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:46 (0.047718 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/07 14:51:27 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/07 14:51:27 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output_eval/coco_instances_results.json\n",
      "\u001b[32m[10/07 14:51:27 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.21s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/07 14:51:28 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/07 14:51:28 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.51 seconds.\n",
      "\u001b[32m[10/07 14:51:28 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/07 14:51:28 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.15 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.219\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.318\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.243\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.007\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.039\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.270\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.232\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.442\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.465\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.040\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.129\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.558\n",
      "\u001b[32m[10/07 14:51:28 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 21.897 | 31.762 | 24.277 | 0.706 | 3.869 | 27.035 |\n",
      "\u001b[32m[10/07 14:51:28 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category      | AP     | category    | AP     | category   | AP     |\n",
      "|:--------------|:-------|:------------|:-------|:-----------|:-------|\n",
      "| General trash | 11.280 | Paper       | 21.782 | Paper pack | 20.306 |\n",
      "| Metal         | 23.176 | Glass       | 22.025 | Plastic    | 12.721 |\n",
      "| Styrofoam     | 15.977 | Plastic bag | 43.994 | Battery    | 25.354 |\n",
      "| Clothing      | 22.357 |             |        |            |        |\n",
      "\u001b[32m[10/07 14:51:28 d2.engine.defaults]: \u001b[0mEvaluation results for coco_trash_test in csv format:\n",
      "\u001b[32m[10/07 14:51:28 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[10/07 14:51:28 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[10/07 14:51:28 d2.evaluation.testing]: \u001b[0mcopypaste: 21.8972,31.7620,24.2768,0.7062,3.8695,27.0351\n",
      "\u001b[32m[10/07 14:51:28 d2.utils.events]: \u001b[0m eta: 0:06:17  iter: 1499  total_loss: 0.8916  loss_cls: 0.4135  loss_box_reg: 0.3383  loss_rpn_cls: 0.03664  loss_rpn_loc: 0.0325    time: 0.2531  last_time: 0.2528  data_time: 0.0167  last_data_time: 0.0168   lr: 0.001  max_mem: 3504M\n",
      "\u001b[32m[10/07 14:51:33 d2.utils.events]: \u001b[0m eta: 0:06:12  iter: 1519  total_loss: 0.7173  loss_cls: 0.4326  loss_box_reg: 0.2881  loss_rpn_cls: 0.018  loss_rpn_loc: 0.01353    time: 0.2531  last_time: 0.2520  data_time: 0.0169  last_data_time: 0.0159   lr: 0.001  max_mem: 3504M\n",
      "\u001b[32m[10/07 14:51:39 d2.utils.events]: \u001b[0m eta: 0:06:07  iter: 1539  total_loss: 0.9358  loss_cls: 0.496  loss_box_reg: 0.3565  loss_rpn_cls: 0.03236  loss_rpn_loc: 0.04441    time: 0.2531  last_time: 0.2503  data_time: 0.0163  last_data_time: 0.0160   lr: 0.001  max_mem: 3504M\n",
      "\u001b[32m[10/07 14:51:44 d2.utils.events]: \u001b[0m eta: 0:06:02  iter: 1559  total_loss: 0.7737  loss_cls: 0.4486  loss_box_reg: 0.2862  loss_rpn_cls: 0.01702  loss_rpn_loc: 0.01972    time: 0.2531  last_time: 0.2503  data_time: 0.0168  last_data_time: 0.0162   lr: 0.001  max_mem: 3504M\n",
      "\u001b[32m[10/07 14:51:49 d2.utils.events]: \u001b[0m eta: 0:05:57  iter: 1579  total_loss: 0.956  loss_cls: 0.5112  loss_box_reg: 0.3737  loss_rpn_cls: 0.03723  loss_rpn_loc: 0.0333    time: 0.2530  last_time: 0.2594  data_time: 0.0170  last_data_time: 0.0150   lr: 0.001  max_mem: 3504M\n",
      "\u001b[32m[10/07 14:51:54 d2.utils.events]: \u001b[0m eta: 0:05:52  iter: 1599  total_loss: 0.7909  loss_cls: 0.4289  loss_box_reg: 0.3029  loss_rpn_cls: 0.0196  loss_rpn_loc: 0.01986    time: 0.2531  last_time: 0.2530  data_time: 0.0170  last_data_time: 0.0163   lr: 0.001  max_mem: 3504M\n",
      "\u001b[32m[10/07 14:51:59 d2.utils.events]: \u001b[0m eta: 0:05:47  iter: 1619  total_loss: 0.9074  loss_cls: 0.4747  loss_box_reg: 0.3261  loss_rpn_cls: 0.01828  loss_rpn_loc: 0.03103    time: 0.2531  last_time: 0.2539  data_time: 0.0173  last_data_time: 0.0181   lr: 0.001  max_mem: 3504M\n",
      "\u001b[32m[10/07 14:52:04 d2.utils.events]: \u001b[0m eta: 0:05:42  iter: 1639  total_loss: 0.7275  loss_cls: 0.4137  loss_box_reg: 0.2716  loss_rpn_cls: 0.02022  loss_rpn_loc: 0.02585    time: 0.2531  last_time: 0.2587  data_time: 0.0177  last_data_time: 0.0235   lr: 0.001  max_mem: 3504M\n",
      "\u001b[32m[10/07 14:52:09 d2.utils.events]: \u001b[0m eta: 0:05:37  iter: 1659  total_loss: 0.8874  loss_cls: 0.4749  loss_box_reg: 0.3487  loss_rpn_cls: 0.03141  loss_rpn_loc: 0.03844    time: 0.2530  last_time: 0.2528  data_time: 0.0169  last_data_time: 0.0166   lr: 0.001  max_mem: 3504M\n",
      "\u001b[32m[10/07 14:52:14 d2.utils.events]: \u001b[0m eta: 0:05:32  iter: 1679  total_loss: 0.8036  loss_cls: 0.4564  loss_box_reg: 0.2754  loss_rpn_cls: 0.02236  loss_rpn_loc: 0.02514    time: 0.2530  last_time: 0.2521  data_time: 0.0167  last_data_time: 0.0160   lr: 0.001  max_mem: 3504M\n",
      "\u001b[32m[10/07 14:52:20 d2.utils.events]: \u001b[0m eta: 0:05:27  iter: 1699  total_loss: 0.7619  loss_cls: 0.4127  loss_box_reg: 0.3091  loss_rpn_cls: 0.03116  loss_rpn_loc: 0.04308    time: 0.2531  last_time: 0.2527  data_time: 0.0172  last_data_time: 0.0161   lr: 0.001  max_mem: 3504M\n",
      "\u001b[32m[10/07 14:52:25 d2.utils.events]: \u001b[0m eta: 0:05:22  iter: 1719  total_loss: 0.7703  loss_cls: 0.4302  loss_box_reg: 0.3035  loss_rpn_cls: 0.01264  loss_rpn_loc: 0.01982    time: 0.2530  last_time: 0.2496  data_time: 0.0163  last_data_time: 0.0161   lr: 0.001  max_mem: 3504M\n",
      "\u001b[32m[10/07 14:52:30 d2.utils.events]: \u001b[0m eta: 0:05:17  iter: 1739  total_loss: 0.7477  loss_cls: 0.4018  loss_box_reg: 0.2745  loss_rpn_cls: 0.0131  loss_rpn_loc: 0.01887    time: 0.2530  last_time: 0.2551  data_time: 0.0170  last_data_time: 0.0195   lr: 0.001  max_mem: 3504M\n",
      "\u001b[32m[10/07 14:52:35 d2.utils.events]: \u001b[0m eta: 0:05:12  iter: 1759  total_loss: 0.8175  loss_cls: 0.4302  loss_box_reg: 0.3137  loss_rpn_cls: 0.017  loss_rpn_loc: 0.02194    time: 0.2530  last_time: 0.2556  data_time: 0.0179  last_data_time: 0.0216   lr: 0.001  max_mem: 3504M\n",
      "\u001b[32m[10/07 14:52:40 d2.utils.events]: \u001b[0m eta: 0:05:07  iter: 1779  total_loss: 0.7041  loss_cls: 0.402  loss_box_reg: 0.2844  loss_rpn_cls: 0.02153  loss_rpn_loc: 0.0393    time: 0.2531  last_time: 0.2622  data_time: 0.0173  last_data_time: 0.0167   lr: 0.001  max_mem: 3504M\n",
      "\u001b[32m[10/07 14:52:45 d2.utils.events]: \u001b[0m eta: 0:05:02  iter: 1799  total_loss: 0.7764  loss_cls: 0.4259  loss_box_reg: 0.293  loss_rpn_cls: 0.02386  loss_rpn_loc: 0.02343    time: 0.2531  last_time: 0.2513  data_time: 0.0172  last_data_time: 0.0181   lr: 0.001  max_mem: 3504M\n",
      "\u001b[32m[10/07 14:52:50 d2.utils.events]: \u001b[0m eta: 0:04:57  iter: 1819  total_loss: 0.7349  loss_cls: 0.3809  loss_box_reg: 0.2819  loss_rpn_cls: 0.02947  loss_rpn_loc: 0.03484    time: 0.2531  last_time: 0.2492  data_time: 0.0180  last_data_time: 0.0165   lr: 0.001  max_mem: 3504M\n",
      "\u001b[32m[10/07 14:52:56 d2.utils.events]: \u001b[0m eta: 0:04:52  iter: 1839  total_loss: 0.6267  loss_cls: 0.3295  loss_box_reg: 0.2326  loss_rpn_cls: 0.01361  loss_rpn_loc: 0.02276    time: 0.2532  last_time: 0.2501  data_time: 0.0179  last_data_time: 0.0154   lr: 0.001  max_mem: 3504M\n",
      "\u001b[32m[10/07 14:53:01 d2.utils.events]: \u001b[0m eta: 0:04:47  iter: 1859  total_loss: 0.6475  loss_cls: 0.3719  loss_box_reg: 0.2567  loss_rpn_cls: 0.01656  loss_rpn_loc: 0.01568    time: 0.2531  last_time: 0.2519  data_time: 0.0170  last_data_time: 0.0181   lr: 0.001  max_mem: 3508M\n",
      "\u001b[32m[10/07 14:53:06 d2.utils.events]: \u001b[0m eta: 0:04:42  iter: 1879  total_loss: 0.8195  loss_cls: 0.4522  loss_box_reg: 0.3326  loss_rpn_cls: 0.0229  loss_rpn_loc: 0.02369    time: 0.2531  last_time: 0.2672  data_time: 0.0177  last_data_time: 0.0213   lr: 0.001  max_mem: 3508M\n",
      "\u001b[32m[10/07 14:53:11 d2.utils.events]: \u001b[0m eta: 0:04:37  iter: 1899  total_loss: 0.7448  loss_cls: 0.4111  loss_box_reg: 0.265  loss_rpn_cls: 0.02388  loss_rpn_loc: 0.02487    time: 0.2532  last_time: 0.2603  data_time: 0.0181  last_data_time: 0.0226   lr: 0.001  max_mem: 3508M\n",
      "\u001b[32m[10/07 14:53:16 d2.utils.events]: \u001b[0m eta: 0:04:32  iter: 1919  total_loss: 0.6963  loss_cls: 0.3944  loss_box_reg: 0.2624  loss_rpn_cls: 0.01775  loss_rpn_loc: 0.01693    time: 0.2532  last_time: 0.2497  data_time: 0.0175  last_data_time: 0.0169   lr: 0.001  max_mem: 3508M\n",
      "\u001b[32m[10/07 14:53:21 d2.utils.events]: \u001b[0m eta: 0:04:27  iter: 1939  total_loss: 0.813  loss_cls: 0.4381  loss_box_reg: 0.2814  loss_rpn_cls: 0.02417  loss_rpn_loc: 0.04015    time: 0.2532  last_time: 0.2590  data_time: 0.0174  last_data_time: 0.0210   lr: 0.001  max_mem: 3508M\n",
      "\u001b[32m[10/07 14:53:26 d2.utils.events]: \u001b[0m eta: 0:04:22  iter: 1959  total_loss: 0.7694  loss_cls: 0.417  loss_box_reg: 0.3403  loss_rpn_cls: 0.01996  loss_rpn_loc: 0.02589    time: 0.2532  last_time: 0.2558  data_time: 0.0178  last_data_time: 0.0169   lr: 0.001  max_mem: 3508M\n",
      "\u001b[32m[10/07 14:53:32 d2.utils.events]: \u001b[0m eta: 0:04:17  iter: 1979  total_loss: 0.7201  loss_cls: 0.4096  loss_box_reg: 0.2583  loss_rpn_cls: 0.02726  loss_rpn_loc: 0.02628    time: 0.2533  last_time: 0.2525  data_time: 0.0176  last_data_time: 0.0162   lr: 0.001  max_mem: 3508M\n",
      "\u001b[32m[10/07 14:53:37 d2.utils.events]: \u001b[0m eta: 0:04:12  iter: 1999  total_loss: 0.6496  loss_cls: 0.3809  loss_box_reg: 0.2688  loss_rpn_cls: 0.01863  loss_rpn_loc: 0.02941    time: 0.2533  last_time: 0.2657  data_time: 0.0184  last_data_time: 0.0190   lr: 0.001  max_mem: 3508M\n",
      "\u001b[32m[10/07 14:53:42 d2.utils.events]: \u001b[0m eta: 0:04:07  iter: 2019  total_loss: 0.6421  loss_cls: 0.3618  loss_box_reg: 0.2415  loss_rpn_cls: 0.01747  loss_rpn_loc: 0.0202    time: 0.2533  last_time: 0.2603  data_time: 0.0170  last_data_time: 0.0171   lr: 0.001  max_mem: 3508M\n",
      "\u001b[32m[10/07 14:53:47 d2.utils.events]: \u001b[0m eta: 0:04:02  iter: 2039  total_loss: 0.7586  loss_cls: 0.4066  loss_box_reg: 0.2764  loss_rpn_cls: 0.01936  loss_rpn_loc: 0.02577    time: 0.2533  last_time: 0.2519  data_time: 0.0172  last_data_time: 0.0171   lr: 0.001  max_mem: 3508M\n",
      "\u001b[32m[10/07 14:53:52 d2.utils.events]: \u001b[0m eta: 0:03:57  iter: 2059  total_loss: 0.8062  loss_cls: 0.45  loss_box_reg: 0.2832  loss_rpn_cls: 0.01582  loss_rpn_loc: 0.03119    time: 0.2533  last_time: 0.2495  data_time: 0.0168  last_data_time: 0.0163   lr: 0.001  max_mem: 3508M\n",
      "\u001b[32m[10/07 14:53:57 d2.utils.events]: \u001b[0m eta: 0:03:52  iter: 2079  total_loss: 0.7021  loss_cls: 0.4042  loss_box_reg: 0.2771  loss_rpn_cls: 0.01775  loss_rpn_loc: 0.0218    time: 0.2533  last_time: 0.2529  data_time: 0.0178  last_data_time: 0.0186   lr: 0.001  max_mem: 3508M\n",
      "\u001b[32m[10/07 14:54:02 d2.utils.events]: \u001b[0m eta: 0:03:47  iter: 2099  total_loss: 0.9102  loss_cls: 0.4375  loss_box_reg: 0.3345  loss_rpn_cls: 0.0228  loss_rpn_loc: 0.0361    time: 0.2533  last_time: 0.2526  data_time: 0.0180  last_data_time: 0.0157   lr: 0.001  max_mem: 3508M\n",
      "\u001b[32m[10/07 14:54:08 d2.utils.events]: \u001b[0m eta: 0:03:42  iter: 2119  total_loss: 0.7855  loss_cls: 0.394  loss_box_reg: 0.3087  loss_rpn_cls: 0.01944  loss_rpn_loc: 0.02013    time: 0.2533  last_time: 0.2521  data_time: 0.0164  last_data_time: 0.0163   lr: 0.001  max_mem: 3508M\n",
      "\u001b[32m[10/07 14:54:13 d2.utils.events]: \u001b[0m eta: 0:03:37  iter: 2139  total_loss: 0.8514  loss_cls: 0.3938  loss_box_reg: 0.3137  loss_rpn_cls: 0.01396  loss_rpn_loc: 0.02402    time: 0.2533  last_time: 0.2503  data_time: 0.0169  last_data_time: 0.0168   lr: 0.001  max_mem: 3508M\n",
      "\u001b[32m[10/07 14:54:18 d2.utils.events]: \u001b[0m eta: 0:03:31  iter: 2159  total_loss: 0.7833  loss_cls: 0.4595  loss_box_reg: 0.2855  loss_rpn_cls: 0.02671  loss_rpn_loc: 0.042    time: 0.2533  last_time: 0.2529  data_time: 0.0170  last_data_time: 0.0165   lr: 0.001  max_mem: 3508M\n",
      "\u001b[32m[10/07 14:54:23 d2.utils.events]: \u001b[0m eta: 0:03:26  iter: 2179  total_loss: 0.675  loss_cls: 0.3968  loss_box_reg: 0.2537  loss_rpn_cls: 0.017  loss_rpn_loc: 0.02347    time: 0.2534  last_time: 0.2552  data_time: 0.0168  last_data_time: 0.0194   lr: 0.001  max_mem: 3508M\n",
      "\u001b[32m[10/07 14:54:28 d2.utils.events]: \u001b[0m eta: 0:03:21  iter: 2199  total_loss: 0.7763  loss_cls: 0.4352  loss_box_reg: 0.2744  loss_rpn_cls: 0.02187  loss_rpn_loc: 0.02884    time: 0.2534  last_time: 0.2535  data_time: 0.0177  last_data_time: 0.0178   lr: 0.001  max_mem: 3508M\n",
      "\u001b[32m[10/07 14:54:33 d2.utils.events]: \u001b[0m eta: 0:03:16  iter: 2219  total_loss: 0.8284  loss_cls: 0.4331  loss_box_reg: 0.2983  loss_rpn_cls: 0.018  loss_rpn_loc: 0.02111    time: 0.2534  last_time: 0.2581  data_time: 0.0176  last_data_time: 0.0252   lr: 0.001  max_mem: 3508M\n",
      "\u001b[32m[10/07 14:54:39 d2.utils.events]: \u001b[0m eta: 0:03:11  iter: 2239  total_loss: 0.5784  loss_cls: 0.358  loss_box_reg: 0.2165  loss_rpn_cls: 0.01252  loss_rpn_loc: 0.009787    time: 0.2534  last_time: 0.2626  data_time: 0.0184  last_data_time: 0.0200   lr: 0.001  max_mem: 3508M\n",
      "\u001b[32m[10/07 14:54:44 d2.utils.events]: \u001b[0m eta: 0:03:06  iter: 2259  total_loss: 0.6826  loss_cls: 0.349  loss_box_reg: 0.2655  loss_rpn_cls: 0.0178  loss_rpn_loc: 0.02067    time: 0.2534  last_time: 0.2554  data_time: 0.0171  last_data_time: 0.0162   lr: 0.001  max_mem: 3508M\n",
      "\u001b[32m[10/07 14:54:49 d2.utils.events]: \u001b[0m eta: 0:03:01  iter: 2279  total_loss: 0.6975  loss_cls: 0.3661  loss_box_reg: 0.2582  loss_rpn_cls: 0.02008  loss_rpn_loc: 0.02159    time: 0.2534  last_time: 0.2578  data_time: 0.0165  last_data_time: 0.0149   lr: 0.001  max_mem: 3508M\n",
      "\u001b[32m[10/07 14:54:54 d2.utils.events]: \u001b[0m eta: 0:02:56  iter: 2299  total_loss: 0.7066  loss_cls: 0.3639  loss_box_reg: 0.2659  loss_rpn_cls: 0.02211  loss_rpn_loc: 0.03026    time: 0.2535  last_time: 0.2539  data_time: 0.0174  last_data_time: 0.0182   lr: 0.001  max_mem: 3508M\n",
      "\u001b[32m[10/07 14:54:59 d2.utils.events]: \u001b[0m eta: 0:02:51  iter: 2319  total_loss: 0.8403  loss_cls: 0.4114  loss_box_reg: 0.3197  loss_rpn_cls: 0.02527  loss_rpn_loc: 0.03533    time: 0.2535  last_time: 0.2519  data_time: 0.0177  last_data_time: 0.0174   lr: 0.001  max_mem: 3508M\n",
      "\u001b[32m[10/07 14:55:04 d2.utils.events]: \u001b[0m eta: 0:02:46  iter: 2339  total_loss: 0.7304  loss_cls: 0.4174  loss_box_reg: 0.2608  loss_rpn_cls: 0.01727  loss_rpn_loc: 0.02319    time: 0.2535  last_time: 0.2507  data_time: 0.0170  last_data_time: 0.0173   lr: 0.001  max_mem: 3508M\n",
      "\u001b[32m[10/07 14:55:10 d2.utils.events]: \u001b[0m eta: 0:02:41  iter: 2359  total_loss: 0.6619  loss_cls: 0.4104  loss_box_reg: 0.2565  loss_rpn_cls: 0.01817  loss_rpn_loc: 0.01785    time: 0.2536  last_time: 0.2643  data_time: 0.0173  last_data_time: 0.0167   lr: 0.001  max_mem: 3508M\n",
      "\u001b[32m[10/07 14:55:15 d2.utils.events]: \u001b[0m eta: 0:02:36  iter: 2379  total_loss: 0.7266  loss_cls: 0.404  loss_box_reg: 0.276  loss_rpn_cls: 0.01423  loss_rpn_loc: 0.02803    time: 0.2536  last_time: 0.2523  data_time: 0.0177  last_data_time: 0.0168   lr: 0.001  max_mem: 3508M\n",
      "\u001b[32m[10/07 14:55:20 d2.utils.events]: \u001b[0m eta: 0:02:31  iter: 2399  total_loss: 0.8792  loss_cls: 0.483  loss_box_reg: 0.2921  loss_rpn_cls: 0.028  loss_rpn_loc: 0.03305    time: 0.2537  last_time: 0.2511  data_time: 0.0172  last_data_time: 0.0168   lr: 0.001  max_mem: 3508M\n",
      "\u001b[32m[10/07 14:55:25 d2.utils.events]: \u001b[0m eta: 0:02:26  iter: 2419  total_loss: 0.7242  loss_cls: 0.4049  loss_box_reg: 0.2528  loss_rpn_cls: 0.01925  loss_rpn_loc: 0.03    time: 0.2537  last_time: 0.2523  data_time: 0.0189  last_data_time: 0.0169   lr: 0.001  max_mem: 3508M\n",
      "\u001b[32m[10/07 14:55:31 d2.utils.events]: \u001b[0m eta: 0:02:21  iter: 2439  total_loss: 0.6811  loss_cls: 0.3625  loss_box_reg: 0.2568  loss_rpn_cls: 0.01571  loss_rpn_loc: 0.01986    time: 0.2537  last_time: 0.2486  data_time: 0.0174  last_data_time: 0.0166   lr: 0.001  max_mem: 3508M\n",
      "\u001b[32m[10/07 14:55:36 d2.utils.events]: \u001b[0m eta: 0:02:16  iter: 2459  total_loss: 0.7783  loss_cls: 0.4188  loss_box_reg: 0.263  loss_rpn_cls: 0.01921  loss_rpn_loc: 0.03718    time: 0.2537  last_time: 0.2631  data_time: 0.0167  last_data_time: 0.0162   lr: 0.001  max_mem: 3508M\n",
      "\u001b[32m[10/07 14:55:41 d2.utils.events]: \u001b[0m eta: 0:02:11  iter: 2479  total_loss: 0.8185  loss_cls: 0.4322  loss_box_reg: 0.3122  loss_rpn_cls: 0.02268  loss_rpn_loc: 0.02558    time: 0.2537  last_time: 0.2512  data_time: 0.0166  last_data_time: 0.0149   lr: 0.001  max_mem: 3508M\n",
      "\u001b[32m[10/07 14:55:46 d2.utils.events]: \u001b[0m eta: 0:02:06  iter: 2499  total_loss: 0.8017  loss_cls: 0.4321  loss_box_reg: 0.3184  loss_rpn_cls: 0.01981  loss_rpn_loc: 0.02612    time: 0.2537  last_time: 0.2537  data_time: 0.0166  last_data_time: 0.0165   lr: 0.001  max_mem: 3508M\n",
      "\u001b[32m[10/07 14:55:51 d2.utils.events]: \u001b[0m eta: 0:02:01  iter: 2519  total_loss: 0.7791  loss_cls: 0.4437  loss_box_reg: 0.2811  loss_rpn_cls: 0.02004  loss_rpn_loc: 0.02933    time: 0.2537  last_time: 0.2621  data_time: 0.0173  last_data_time: 0.0267   lr: 0.001  max_mem: 3508M\n",
      "\u001b[32m[10/07 14:55:56 d2.utils.events]: \u001b[0m eta: 0:01:56  iter: 2539  total_loss: 0.7484  loss_cls: 0.3956  loss_box_reg: 0.2736  loss_rpn_cls: 0.0182  loss_rpn_loc: 0.0207    time: 0.2537  last_time: 0.2567  data_time: 0.0172  last_data_time: 0.0162   lr: 0.001  max_mem: 3508M\n",
      "\u001b[32m[10/07 14:56:01 d2.utils.events]: \u001b[0m eta: 0:01:51  iter: 2559  total_loss: 0.7307  loss_cls: 0.3976  loss_box_reg: 0.2569  loss_rpn_cls: 0.01236  loss_rpn_loc: 0.02897    time: 0.2537  last_time: 0.2529  data_time: 0.0171  last_data_time: 0.0173   lr: 0.001  max_mem: 3508M\n",
      "\u001b[32m[10/07 14:56:07 d2.utils.events]: \u001b[0m eta: 0:01:46  iter: 2579  total_loss: 0.708  loss_cls: 0.3772  loss_box_reg: 0.2757  loss_rpn_cls: 0.01597  loss_rpn_loc: 0.03021    time: 0.2537  last_time: 0.2530  data_time: 0.0176  last_data_time: 0.0171   lr: 0.001  max_mem: 3508M\n",
      "\u001b[32m[10/07 14:56:12 d2.utils.events]: \u001b[0m eta: 0:01:41  iter: 2599  total_loss: 0.7448  loss_cls: 0.3779  loss_box_reg: 0.2845  loss_rpn_cls: 0.02416  loss_rpn_loc: 0.02189    time: 0.2537  last_time: 0.2632  data_time: 0.0166  last_data_time: 0.0163   lr: 0.001  max_mem: 3508M\n",
      "\u001b[32m[10/07 14:56:17 d2.utils.events]: \u001b[0m eta: 0:01:36  iter: 2619  total_loss: 0.7567  loss_cls: 0.4037  loss_box_reg: 0.2667  loss_rpn_cls: 0.01794  loss_rpn_loc: 0.01326    time: 0.2538  last_time: 0.2595  data_time: 0.0166  last_data_time: 0.0161   lr: 0.001  max_mem: 3508M\n",
      "\u001b[32m[10/07 14:56:22 d2.utils.events]: \u001b[0m eta: 0:01:31  iter: 2639  total_loss: 0.6903  loss_cls: 0.3721  loss_box_reg: 0.2379  loss_rpn_cls: 0.01479  loss_rpn_loc: 0.02253    time: 0.2538  last_time: 0.2607  data_time: 0.0175  last_data_time: 0.0158   lr: 0.001  max_mem: 3508M\n",
      "\u001b[32m[10/07 14:56:27 d2.utils.events]: \u001b[0m eta: 0:01:26  iter: 2659  total_loss: 0.8349  loss_cls: 0.4399  loss_box_reg: 0.3032  loss_rpn_cls: 0.01842  loss_rpn_loc: 0.02489    time: 0.2538  last_time: 0.2515  data_time: 0.0170  last_data_time: 0.0166   lr: 0.001  max_mem: 3508M\n",
      "\u001b[32m[10/07 14:56:32 d2.utils.events]: \u001b[0m eta: 0:01:21  iter: 2679  total_loss: 0.8758  loss_cls: 0.5023  loss_box_reg: 0.3048  loss_rpn_cls: 0.02438  loss_rpn_loc: 0.03279    time: 0.2538  last_time: 0.2505  data_time: 0.0164  last_data_time: 0.0163   lr: 0.001  max_mem: 3508M\n",
      "\u001b[32m[10/07 14:56:37 d2.utils.events]: \u001b[0m eta: 0:01:15  iter: 2699  total_loss: 0.6636  loss_cls: 0.3689  loss_box_reg: 0.2295  loss_rpn_cls: 0.01418  loss_rpn_loc: 0.02526    time: 0.2538  last_time: 0.2498  data_time: 0.0162  last_data_time: 0.0160   lr: 0.001  max_mem: 3508M\n",
      "\u001b[32m[10/07 14:56:43 d2.utils.events]: \u001b[0m eta: 0:01:10  iter: 2719  total_loss: 0.6019  loss_cls: 0.381  loss_box_reg: 0.219  loss_rpn_cls: 0.01209  loss_rpn_loc: 0.01467    time: 0.2537  last_time: 0.2481  data_time: 0.0160  last_data_time: 0.0161   lr: 0.001  max_mem: 3508M\n",
      "\u001b[32m[10/07 14:56:48 d2.utils.events]: \u001b[0m eta: 0:01:05  iter: 2739  total_loss: 0.7111  loss_cls: 0.3923  loss_box_reg: 0.3018  loss_rpn_cls: 0.01604  loss_rpn_loc: 0.02065    time: 0.2537  last_time: 0.2511  data_time: 0.0165  last_data_time: 0.0161   lr: 0.001  max_mem: 3508M\n",
      "\u001b[32m[10/07 14:56:53 d2.utils.events]: \u001b[0m eta: 0:01:00  iter: 2759  total_loss: 0.7005  loss_cls: 0.3886  loss_box_reg: 0.2247  loss_rpn_cls: 0.01594  loss_rpn_loc: 0.02179    time: 0.2537  last_time: 0.2505  data_time: 0.0160  last_data_time: 0.0159   lr: 0.001  max_mem: 3508M\n",
      "\u001b[32m[10/07 14:56:58 d2.utils.events]: \u001b[0m eta: 0:00:55  iter: 2779  total_loss: 0.6862  loss_cls: 0.3621  loss_box_reg: 0.2989  loss_rpn_cls: 0.01787  loss_rpn_loc: 0.0369    time: 0.2537  last_time: 0.2523  data_time: 0.0168  last_data_time: 0.0170   lr: 0.001  max_mem: 3508M\n",
      "\u001b[32m[10/07 14:57:03 d2.utils.events]: \u001b[0m eta: 0:00:50  iter: 2799  total_loss: 0.6602  loss_cls: 0.3601  loss_box_reg: 0.2347  loss_rpn_cls: 0.02237  loss_rpn_loc: 0.01492    time: 0.2537  last_time: 0.2543  data_time: 0.0169  last_data_time: 0.0167   lr: 0.001  max_mem: 3508M\n",
      "\u001b[32m[10/07 14:57:08 d2.utils.events]: \u001b[0m eta: 0:00:45  iter: 2819  total_loss: 0.6802  loss_cls: 0.3927  loss_box_reg: 0.2643  loss_rpn_cls: 0.01363  loss_rpn_loc: 0.02828    time: 0.2537  last_time: 0.2539  data_time: 0.0171  last_data_time: 0.0202   lr: 0.001  max_mem: 3508M\n",
      "\u001b[32m[10/07 14:57:13 d2.utils.events]: \u001b[0m eta: 0:00:40  iter: 2839  total_loss: 0.8485  loss_cls: 0.4368  loss_box_reg: 0.3286  loss_rpn_cls: 0.01585  loss_rpn_loc: 0.01868    time: 0.2537  last_time: 0.2613  data_time: 0.0171  last_data_time: 0.0167   lr: 0.001  max_mem: 3508M\n",
      "\u001b[32m[10/07 14:57:19 d2.utils.events]: \u001b[0m eta: 0:00:35  iter: 2859  total_loss: 0.682  loss_cls: 0.356  loss_box_reg: 0.2895  loss_rpn_cls: 0.01941  loss_rpn_loc: 0.03154    time: 0.2538  last_time: 0.2533  data_time: 0.0177  last_data_time: 0.0164   lr: 0.001  max_mem: 3508M\n",
      "\u001b[32m[10/07 14:57:24 d2.utils.events]: \u001b[0m eta: 0:00:30  iter: 2879  total_loss: 0.7831  loss_cls: 0.3862  loss_box_reg: 0.3126  loss_rpn_cls: 0.01729  loss_rpn_loc: 0.02442    time: 0.2538  last_time: 0.2515  data_time: 0.0176  last_data_time: 0.0169   lr: 0.001  max_mem: 3508M\n",
      "\u001b[32m[10/07 14:57:29 d2.utils.events]: \u001b[0m eta: 0:00:25  iter: 2899  total_loss: 0.8062  loss_cls: 0.3901  loss_box_reg: 0.2695  loss_rpn_cls: 0.02853  loss_rpn_loc: 0.05926    time: 0.2538  last_time: 0.2572  data_time: 0.0184  last_data_time: 0.0197   lr: 0.001  max_mem: 3508M\n",
      "\u001b[32m[10/07 14:57:34 d2.utils.events]: \u001b[0m eta: 0:00:20  iter: 2919  total_loss: 0.7655  loss_cls: 0.4238  loss_box_reg: 0.3051  loss_rpn_cls: 0.01909  loss_rpn_loc: 0.02362    time: 0.2538  last_time: 0.2500  data_time: 0.0171  last_data_time: 0.0166   lr: 0.001  max_mem: 3508M\n",
      "\u001b[32m[10/07 14:57:39 d2.utils.events]: \u001b[0m eta: 0:00:15  iter: 2939  total_loss: 0.7483  loss_cls: 0.4177  loss_box_reg: 0.2668  loss_rpn_cls: 0.01741  loss_rpn_loc: 0.02758    time: 0.2538  last_time: 0.2563  data_time: 0.0177  last_data_time: 0.0182   lr: 0.001  max_mem: 3508M\n",
      "\u001b[32m[10/07 14:57:44 d2.utils.events]: \u001b[0m eta: 0:00:10  iter: 2959  total_loss: 0.6924  loss_cls: 0.3453  loss_box_reg: 0.3095  loss_rpn_cls: 0.02249  loss_rpn_loc: 0.02805    time: 0.2538  last_time: 0.2521  data_time: 0.0169  last_data_time: 0.0161   lr: 0.001  max_mem: 3508M\n",
      "\u001b[32m[10/07 14:57:49 d2.utils.events]: \u001b[0m eta: 0:00:05  iter: 2979  total_loss: 0.7226  loss_cls: 0.3646  loss_box_reg: 0.2787  loss_rpn_cls: 0.02286  loss_rpn_loc: 0.02158    time: 0.2538  last_time: 0.2563  data_time: 0.0178  last_data_time: 0.0235   lr: 0.001  max_mem: 3508M\n",
      "\u001b[32m[10/07 14:57:57 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 2999  total_loss: 0.8147  loss_cls: 0.4009  loss_box_reg: 0.3293  loss_rpn_cls: 0.01459  loss_rpn_loc: 0.03872    time: 0.2538  last_time: 0.2656  data_time: 0.0174  last_data_time: 0.0169   lr: 0.001  max_mem: 3508M\n",
      "\u001b[32m[10/07 14:57:57 d2.engine.hooks]: \u001b[0mOverall training speed: 2998 iterations in 0:12:40 (0.2538 s / it)\n",
      "\u001b[32m[10/07 14:57:57 d2.engine.hooks]: \u001b[0mTotal training time: 0:13:42 (0:01:01 on hooks)\n",
      "\u001b[32m[10/07 14:57:57 d2.data.datasets.coco]: \u001b[0mLoaded 977 images in COCO format from /data/ephemeral/home/baseline/detectron2/val_split.json\n",
      "\u001b[32m[10/07 14:57:57 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/07 14:57:57 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[10/07 14:57:57 d2.data.common]: \u001b[0mSerializing 977 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/07 14:57:57 d2.data.common]: \u001b[0mSerialized dataset takes 0.43 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/07 14:57:57 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[10/07 14:57:57 d2.evaluation.evaluator]: \u001b[0mStart inference on 977 batches\n",
      "\u001b[32m[10/07 14:57:58 d2.evaluation.evaluator]: \u001b[0mInference done 11/977. Dataloading: 0.0019 s/iter. Inference: 0.0485 s/iter. Eval: 0.0003 s/iter. Total: 0.0507 s/iter. ETA=0:00:48\n",
      "\u001b[32m[10/07 14:58:03 d2.evaluation.evaluator]: \u001b[0mInference done 115/977. Dataloading: 0.0015 s/iter. Inference: 0.0465 s/iter. Eval: 0.0003 s/iter. Total: 0.0484 s/iter. ETA=0:00:41\n",
      "\u001b[32m[10/07 14:58:08 d2.evaluation.evaluator]: \u001b[0mInference done 219/977. Dataloading: 0.0015 s/iter. Inference: 0.0466 s/iter. Eval: 0.0003 s/iter. Total: 0.0484 s/iter. ETA=0:00:36\n",
      "\u001b[32m[10/07 14:58:13 d2.evaluation.evaluator]: \u001b[0mInference done 321/977. Dataloading: 0.0015 s/iter. Inference: 0.0468 s/iter. Eval: 0.0003 s/iter. Total: 0.0486 s/iter. ETA=0:00:31\n",
      "\u001b[32m[10/07 14:58:18 d2.evaluation.evaluator]: \u001b[0mInference done 424/977. Dataloading: 0.0015 s/iter. Inference: 0.0469 s/iter. Eval: 0.0003 s/iter. Total: 0.0487 s/iter. ETA=0:00:26\n",
      "\u001b[32m[10/07 14:58:23 d2.evaluation.evaluator]: \u001b[0mInference done 528/977. Dataloading: 0.0015 s/iter. Inference: 0.0468 s/iter. Eval: 0.0003 s/iter. Total: 0.0486 s/iter. ETA=0:00:21\n",
      "\u001b[32m[10/07 14:58:28 d2.evaluation.evaluator]: \u001b[0mInference done 634/977. Dataloading: 0.0015 s/iter. Inference: 0.0466 s/iter. Eval: 0.0003 s/iter. Total: 0.0484 s/iter. ETA=0:00:16\n",
      "\u001b[32m[10/07 14:58:33 d2.evaluation.evaluator]: \u001b[0mInference done 736/977. Dataloading: 0.0015 s/iter. Inference: 0.0467 s/iter. Eval: 0.0003 s/iter. Total: 0.0485 s/iter. ETA=0:00:11\n",
      "\u001b[32m[10/07 14:58:38 d2.evaluation.evaluator]: \u001b[0mInference done 840/977. Dataloading: 0.0015 s/iter. Inference: 0.0467 s/iter. Eval: 0.0003 s/iter. Total: 0.0485 s/iter. ETA=0:00:06\n",
      "\u001b[32m[10/07 14:58:43 d2.evaluation.evaluator]: \u001b[0mInference done 948/977. Dataloading: 0.0015 s/iter. Inference: 0.0464 s/iter. Eval: 0.0003 s/iter. Total: 0.0483 s/iter. ETA=0:00:01\n",
      "\u001b[32m[10/07 14:58:44 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:47.003231 (0.048357 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/07 14:58:44 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:45 (0.046487 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/07 14:58:44 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/07 14:58:45 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output_eval/coco_instances_results.json\n",
      "\u001b[32m[10/07 14:58:45 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.21s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/07 14:58:45 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/07 14:58:45 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.43 seconds.\n",
      "\u001b[32m[10/07 14:58:45 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/07 14:58:45 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.13 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.297\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.413\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.316\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.037\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.367\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.261\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.482\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.514\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.019\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.151\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.610\n",
      "\u001b[32m[10/07 14:58:45 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 29.716 | 41.267 | 31.582 | 0.599 | 3.736 | 36.742 |\n",
      "\u001b[32m[10/07 14:58:45 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category      | AP     | category    | AP     | category   | AP     |\n",
      "|:--------------|:-------|:------------|:-------|:-----------|:-------|\n",
      "| General trash | 16.245 | Paper       | 23.206 | Paper pack | 32.446 |\n",
      "| Metal         | 29.176 | Glass       | 29.918 | Plastic    | 19.420 |\n",
      "| Styrofoam     | 23.878 | Plastic bag | 48.638 | Battery    | 37.359 |\n",
      "| Clothing      | 36.871 |             |        |            |        |\n",
      "\u001b[32m[10/07 14:58:46 d2.engine.defaults]: \u001b[0mEvaluation results for coco_trash_test in csv format:\n",
      "\u001b[32m[10/07 14:58:46 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[10/07 14:58:46 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[10/07 14:58:46 d2.evaluation.testing]: \u001b[0mcopypaste: 29.7157,41.2666,31.5819,0.5991,3.7358,36.7420\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok = True)\n",
    "\n",
    "trainer = MyTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85ea7c9250e04eb89b4ca062cca48f0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.085 MB of 0.085 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>bbox/AP</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>bbox/AP-Battery</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>bbox/AP-Clothing</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>bbox/AP-General trash</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>bbox/AP-Glass</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>bbox/AP-Metal</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>bbox/AP-Paper</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>bbox/AP-Paper pack</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>bbox/AP-Plastic</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>bbox/AP-Plastic bag</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>bbox/AP-Styrofoam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>bbox/AP50</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>bbox/AP75</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>bbox/APl</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>bbox/APm</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>bbox/APs</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>data_time</td><td>▅▁▂▃▃▂▃▃▂▄▂▄▅▄▃▄▅▄▂▄▄▆▅▃▄▃▄▄▃▄▄▃▄▂▄▅▅██▅</td></tr><tr><td>eta_seconds</td><td>████▇▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>fast_rcnn/cls_accuracy</td><td>▂▂▂▁▁▂▂▃▅▄▄▄▄▄▅▆▅▄▄▅▆▇▄▄▅▇▇▇▇▅█▆▆▆▆▆█▆▅█</td></tr><tr><td>fast_rcnn/false_negative</td><td>▃█▆▃▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▃▃▂▁▂▂▂▁▂▂▂▂▁▂▁▂▂▂▁▂</td></tr><tr><td>fast_rcnn/fg_cls_accuracy</td><td>▁▁▁▁▂▃▃▄▄▄▅▅▅▅▅▅▅▄▄▆▆▅▆▆▆▇▇▆▆▆▇▇▆▇▇▆▆█▇▇</td></tr><tr><td>loss_box_reg</td><td>▇██▇▇▅▄▃▄▃▃▂▂▂▂▂▂▃▂▂▂▂▁▁▁▂▂▁▁▁▁▂▁▂▁▂▂▁▂▂</td></tr><tr><td>loss_cls</td><td>██▃▂▂▁▁▂▂▁▂▂▂▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_rpn_cls</td><td>▄▄▇█▇▇▄▄▄▆▄█▃▅▄▄▁▄█▅▃▅▁▂▂▄▃▄▃▂▂▃▂▄▃▁▃▂▂▆</td></tr><tr><td>loss_rpn_loc</td><td>▆▅▄▃▄▂▅▅▂█▆▅▃▇▃▇▃▂▅▂█▅▂▁▇▂▂▃▄▁▂▄▄▄▄▄▅▃▄▄</td></tr><tr><td>lr</td><td>▁▁▂▂▂▂▃▃▃▃▄▄▅▅▅▇▇███████████████████████</td></tr><tr><td>rank_data_time</td><td>▁▁▁▂▂▂▃▂▅▄▆▄▄▂▂▆▅▅▆▅▆▆▅▅▅▆▅▅█▆▄▄▃▅▄▂▆▅▆▄</td></tr><tr><td>roi_head/num_bg_samples</td><td>▆▆█▄▇▇▁▅▅▆▆▆▃▂▃▄▅▅▂▃▅▆▄▃▅▃▃▂▃▂▄▃▅▃▂▂▂▂▁▄</td></tr><tr><td>roi_head/num_fg_samples</td><td>▁▁▁▄▃█▄▃▆▄▄▃▃▆▅█▅▃▅▆█▅▇▆▄▅▆▄▆▆▅▅▅▄▆▄▄▅▄▆</td></tr><tr><td>rpn/num_neg_anchors</td><td>█▇▆▆▃▅▁▅▆▄▄▄▄▄▆▇▅▆▁▂▂▄▅▃▅▇▇█▁▄▂▆▄▅▇▂▄▅▅▅</td></tr><tr><td>rpn/num_pos_anchors</td><td>▃▂▃▃▅▅▂▄▅▃▅▅▄▄▃▂▂▃▄█▃▆▂▅▃▂▁▄▅▂▅▃▂▇▅▃▄▄▄▆</td></tr><tr><td>time</td><td>▁▃▃▂▂▄▃▃▃▂▂▂▂▃▆▃▄▃▃▂▃▂▂▃▃▃▃▅▃▄▃▃▃██▇▄▂▃▃</td></tr><tr><td>total_loss</td><td>█▅▄▄▄▃▄▂▂▂▃▂▂▂▂▂▂▁▂▁▂▂▂▁▂▂▁▁▁▂▁▁▁▁▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>bbox/AP</td><td>21.9</td></tr><tr><td>bbox/AP-Battery</td><td>25.35</td></tr><tr><td>bbox/AP-Clothing</td><td>22.36</td></tr><tr><td>bbox/AP-General trash</td><td>11.28</td></tr><tr><td>bbox/AP-Glass</td><td>22.02</td></tr><tr><td>bbox/AP-Metal</td><td>23.18</td></tr><tr><td>bbox/AP-Paper</td><td>21.78</td></tr><tr><td>bbox/AP-Paper pack</td><td>20.31</td></tr><tr><td>bbox/AP-Plastic</td><td>12.72</td></tr><tr><td>bbox/AP-Plastic bag</td><td>43.99</td></tr><tr><td>bbox/AP-Styrofoam</td><td>15.98</td></tr><tr><td>bbox/AP50</td><td>31.76</td></tr><tr><td>bbox/AP75</td><td>24.28</td></tr><tr><td>bbox/APl</td><td>27.04</td></tr><tr><td>bbox/APm</td><td>3.869</td></tr><tr><td>bbox/APs</td><td>0.7062</td></tr><tr><td>data_time</td><td>0.01706</td></tr><tr><td>eta_seconds</td><td>48.06</td></tr><tr><td>fast_rcnn/cls_accuracy</td><td>0.8623</td></tr><tr><td>fast_rcnn/false_negative</td><td>0.2845</td></tr><tr><td>fast_rcnn/fg_cls_accuracy</td><td>0.3915</td></tr><tr><td>loss_box_reg</td><td>0.3293</td></tr><tr><td>loss_cls</td><td>0.4009</td></tr><tr><td>loss_rpn_cls</td><td>0.01459</td></tr><tr><td>loss_rpn_loc</td><td>0.03872</td></tr><tr><td>lr</td><td>0.001</td></tr><tr><td>rank_data_time</td><td>0.01706</td></tr><tr><td>roi_head/num_bg_samples</td><td>101.5</td></tr><tr><td>roi_head/num_fg_samples</td><td>26.5</td></tr><tr><td>rpn/num_neg_anchors</td><td>228.2</td></tr><tr><td>rpn/num_pos_anchors</td><td>27.75</td></tr><tr><td>time</td><td>0.2612</td></tr><tr><td>total_loss</td><td>0.8147</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">COCO-Detection/faster_rcnn_R_101_FPN_3x_1007_1443</strong> at: <a href='https://wandb.ai/superl3-naver/level2-objectdetection-cv-13/runs/nxwgp2v1' target=\"_blank\">https://wandb.ai/superl3-naver/level2-objectdetection-cv-13/runs/nxwgp2v1</a><br/> View project at: <a href='https://wandb.ai/superl3-naver/level2-objectdetection-cv-13' target=\"_blank\">https://wandb.ai/superl3-naver/level2-objectdetection-cv-13</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241007_144357-nxwgp2v1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
